{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsjt01817VIr"
      },
      "source": [
        "Notebook for running Multi-task learning *for* biomedical \n",
        "relation extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jznd_hp7bf6"
      },
      "source": [
        "Link to Google Drive, useful for saving models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaECO_wW7RZD",
        "outputId": "b1718806-0770-44cc-bcfd-34659e9752e4"
      },
      "source": [
        "from google.colab  import drive\n",
        "drive.mount(\"/content/gdrive\",force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So2g-Yq5phVF"
      },
      "source": [
        "#Checking available GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqJoQbmu-m9K"
      },
      "source": [
        "Clone repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSfjqWB5-mYY",
        "outputId": "cd0a7740-f80d-4751-9a99-7564986444ff"
      },
      "source": [
        "!git clone https://github.com/IoSylar/Multi-task-Learning-for-Biomedical-Relation-Extraction.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Multi-task-Learning-for-Biomedical-Relation-Extraction'...\n",
            "remote: Enumerating objects: 590, done.\u001b[K\n",
            "remote: Counting objects: 100% (590/590), done.\u001b[K\n",
            "remote: Compressing objects: 100% (423/423), done.\u001b[K\n",
            "remote: Total 590 (delta 157), reused 590 (delta 157), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (590/590), 23.55 MiB | 14.73 MiB/s, done.\n",
            "Resolving deltas: 100% (157/157), done.\n",
            "Checking out files: 100% (646/646), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOnl2nrP7i6X"
      },
      "source": [
        "Script for downloading and preprocessing all clinical NLP datasets. Note that the i2b2 files must be downloaded from the official site under license. Therefore, the DDI2013, Chemprot, and I2B22010 datasets have already been processed offline and are present in the Multi-task-Learning-for-Biomedical-Relation-Extraction/Dataset folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vo008QKpV4m"
      },
      "source": [
        "!bash download_all_task_data.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzg8KaMmpbrN"
      },
      "source": [
        "!pip install bioc\n",
        "!pip install fire"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNP6DpyzpZs3"
      },
      "source": [
        "!bash preprocess_all_classification_datasets.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZFif-Xj7qZb"
      },
      "source": [
        "I move to the main directory and install the requirements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9dfetTBt-ip"
      },
      "source": [
        "%cd \"/content/Multi-task-Learning-for-Biomedical-Relation-Extraction/mt-dnn\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTOmZYJXsWrg"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ae5Q8-H7u8g"
      },
      "source": [
        "You need to install the latest version of apex, so you uninstall and then reinstall apex."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJkORVD-pdlL"
      },
      "source": [
        "!pip3 uninstall apex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_UXKTqVppp9"
      },
      "source": [
        "!git clone https://www.github.com/nvidia/apex\n",
        "%cd apex\n",
        "!python3 setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1DLIQvP7z-6"
      },
      "source": [
        "You should use the link that leads to my Mega.nz account to download the pre-trained roberta model from the clinical NLP paper. This model, originally in PyTorch format (.bin), has been converted to model.pt. Link: https://mega.nz/folder/Bc0CXJaa#qhY1Cp4CGaaBaOGU__bFig. It is recommended to not specify any path, but to use the default choice: mt-dnn_models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlt1GCHJ50ue",
        "outputId": "821d6106-b468-49a0-f154-20ab9e3743b3"
      },
      "source": [
        "import sys, os, urllib.request\n",
        "import time\n",
        "import subprocess\n",
        "import contextlib\n",
        "from IPython.display import clear_output\n",
        "#@markdown <br><center><img src='https://mega.nz/favicon.ico?v=3' height=\"50\" alt=\"MEGA-logo\"/></center>\n",
        "#@markdown <center><h2>Transfer from Mega to GDrive</h2></center><br>\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "if not os.path.exists(f\"{HOME}/.ipython/ocr.py\"):\n",
        "    hCode = \"https://raw.githubusercontent.com/biplobsd/\" \\\n",
        "                \"OneClickRun/master/res/ocr.py\"\n",
        "    urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/ocr.py\")\n",
        "\n",
        "from ocr import (\n",
        "    runSh,\n",
        "    loadingAn,\n",
        ")\n",
        "#@title MEGA public link download\n",
        "URL = \"https://mega.nz/folder/Bc0CXJaa#qhY1Cp4CGaaBaOGU__bFig\" #@param {type:\"string\"}\n",
        "OUTPUT_PATH = \"\" #@param {type:\"string\"}\n",
        "#@markdown #####_*Sometimes this cell doesn't stop itself after the completion of the transfer. In case of that stop the cell manually._\n",
        "if not OUTPUT_PATH:\n",
        "  os.makedirs(\"mt_dnn_models\", exist_ok=True)\n",
        "  OUTPUT_PATH = \"mt_dnn_models\"\n",
        "# MEGAcmd installing\n",
        "if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "    loadingAn()\n",
        "    print(\"Installing MEGA ...\")\n",
        "    runSh('sudo apt-get -y update')\n",
        "    runSh('sudo apt-get -y install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https')\n",
        "    runSh('sudo curl -sL -o /var/cache/apt/archives/MEGAcmd.deb https://mega.nz/linux/MEGAsync/Debian_9.0/amd64/megacmd-Debian_9.0_amd64.deb', output=True)\n",
        "    runSh('sudo dpkg -i /var/cache/apt/archives/MEGAcmd.deb', output=True)\n",
        "    print(\"MEGA is installed.\")\n",
        "    clear_output()\n",
        "\n",
        "# Unix, Windows and old Macintosh end-of-line\n",
        "newlines = ['\\n', '\\r\\n', '\\r']\n",
        "\n",
        "def unbuffered(proc, stream='stdout'):\n",
        "    stream = getattr(proc, stream)\n",
        "    with contextlib.closing(stream):\n",
        "        while True:\n",
        "            out = []\n",
        "            last = stream.read(1)\n",
        "            # Don't loop forever\n",
        "            if last == '' and proc.poll() is not None:\n",
        "                break\n",
        "            while last not in newlines:\n",
        "                # Don't loop forever\n",
        "                if last == '' and proc.poll() is not None:\n",
        "                    break\n",
        "                out.append(last)\n",
        "                last = stream.read(1)\n",
        "            out = ''.join(out)\n",
        "            yield out\n",
        "\n",
        "\n",
        "def transfare():\n",
        "    import codecs\n",
        "    decoder = codecs.getincrementaldecoder(\"UTF-8\")()\n",
        "    cmd = [\"mega-get\", URL, OUTPUT_PATH]\n",
        "    proc = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        # Make all end-of-lines '\\n'\n",
        "        universal_newlines=True,\n",
        "    )\n",
        "    for line in unbuffered(proc):\n",
        "        print(line)\n",
        "        \n",
        "\n",
        "\n",
        "transfare()\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRANSFERRING ||............................................||(0/0 KB:   0.00 %) \u0000\n",
            "TRANSFERRING ||############################################||(0/0 KB: 100.00 %) \u0000\n",
            "Download finished: /content/Multi-task-Learning-for-Biomedical-Relation-Extraction/mt-dnn/mt_dnn_models/robertaFB\n",
            "TRANSFERRING ||########################################||(953/953 MB: 100.00 %) \u0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebUTs5CFDMLj"
      },
      "source": [
        "Each dataset must be pre-processed with prepro_std.py. Each dataset will be of the type ddi2013_train.tsv -dev.tsv - test.tsv. You can insert a local model as in the example, or any model available on huggingface, the root dir in which the datasets should be placed is tutorial. For simplicity, they have already been moved there. The definition of tasks is in tutorial_task_def.yml. Each task must first be defined in this file, then it can be processed. Always refer to the main directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNao58F_FHoP",
        "outputId": "ab2e5a11-58da-4a8c-bc87-ba8d31e1129e"
      },
      "source": [
        "%cd \"/content/Multi-task-Learning-for-Biomedical-Relation-Extraction/mt-dnn\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Multi-task-Learning-for-Biomedical-Relation-Extraction/mt-dnn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_7tTNwItTaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "617ce27a-f7cd-4243-af3a-fecebb13ff4e"
      },
      "source": [
        "!python prepro_std.py --model mt_dnn_models/robertaFB  --root_dir tutorials/ --task_def tutorials/tutorial_task_def.yml"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n",
            "{'input_ids': [0, 22963, 384, 261, 3332, 265, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "10/09/2021 09:23:48 Task chemprot\n",
            "10/09/2021 09:23:48 tutorials/mt_dnn_models/robertaFB/chemprot_train.json\n",
            "10/09/2021 09:23:52 tutorials/mt_dnn_models/robertaFB/chemprot_dev.json\n",
            "10/09/2021 09:23:55 tutorials/mt_dnn_models/robertaFB/chemprot_test.json\n",
            "10/09/2021 09:24:00 Task ddi2013\n",
            "10/09/2021 09:24:00 tutorials/mt_dnn_models/robertaFB/ddi2013_train.json\n",
            "10/09/2021 09:24:08 tutorials/mt_dnn_models/robertaFB/ddi2013_dev.json\n",
            "10/09/2021 09:24:10 tutorials/mt_dnn_models/robertaFB/ddi2013_test.json\n",
            "10/09/2021 09:24:11 Task i2b2\n",
            "10/09/2021 09:24:11 tutorials/mt_dnn_models/robertaFB/i2b2_train.json\n",
            "10/09/2021 09:24:16 tutorials/mt_dnn_models/robertaFB/i2b2_dev.json\n",
            "10/09/2021 09:24:17 tutorials/mt_dnn_models/robertaFB/i2b2_test.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-irvWz1mdwim"
      },
      "source": [
        "Run the multi-task training on the entire dataset. To run single task, specify only one task to use and remove the MTL-related parameters. The directory to save the model and results: output_dir is set by the user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqAXphgXvzKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3700c38b-00c8-4f8f-afde-4f03788d745c"
      },
      "source": [
        "!python train.py --task_def tutorials/tutorial_task_def.yml --data_dir tutorials/mt_dnn_models/robertaFB   --train_datasets ddi2013,chemprot,i2b2 --test_datasets ddi2013,chemprot,i2b2 --epochs=10 --batch_size=8 --bert_model_type=\"roberta\"  --encoder_type=2  --output_dir=\"Addestramento\" --init_checkpoint=\"mt_dnn_models/robertaFB\" --grad_clipping=1.0 --adam_eps=1e-7  --seed=2010 --mtl_opt=1  #--model_ckpt=\"SingleI2B2SEED2040/model_2.pt\" --resume"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/09/2021 09:25:40 Launching the MT-DNN training\n",
            "10/09/2021 09:25:40 Loading tutorials/mt_dnn_models/robertaFB/ddi2013_train.json as task 0\n",
            "Loaded 29333 samples out of 29333\n",
            "10/09/2021 09:25:41 Loading tutorials/mt_dnn_models/robertaFB/chemprot_train.json as task 1\n",
            "Loaded 19460 samples out of 19460\n",
            "10/09/2021 09:25:42 Loading tutorials/mt_dnn_models/robertaFB/i2b2_train.json as task 2\n",
            "Loaded 21384 samples out of 21384\n",
            "False\n",
            "False\n",
            "Loaded 7244 samples out of 7244\n",
            "Loaded 5761 samples out of 5761\n",
            "Loaded 11820 samples out of 11820\n",
            "Loaded 16943 samples out of 16943\n",
            "Loaded 872 samples out of 872\n",
            "Loaded 43000 samples out of 43000\n",
            "10/09/2021 09:25:45 ####################\n",
            "10/09/2021 09:25:45 {'log_file': 'mt-dnn-train.log', 'tensorboard': False, 'tensorboard_logdir': 'tensorboard_logdir', 'init_checkpoint': 'mt_dnn_models/robertaFB', 'data_dir': 'tutorials/mt_dnn_models/robertaFB', 'data_sort_on': False, 'name': 'farmer', 'task_def': 'tutorials/tutorial_task_def.yml', 'train_datasets': ['ddi2013', 'chemprot', 'i2b2'], 'test_datasets': ['ddi2013', 'chemprot', 'i2b2'], 'glue_format_on': False, 'mkd_opt': 0, 'do_padding': False, 'update_bert_opt': 0, 'multi_gpu_on': False, 'mem_cum_type': 'simple', 'answer_num_turn': 5, 'answer_mem_drop_p': 0.1, 'answer_att_hidden_size': 128, 'answer_att_type': 'bilinear', 'answer_rnn_type': 'gru', 'answer_sum_att_type': 'bilinear', 'answer_merge_opt': 1, 'answer_mem_type': 1, 'max_answer_len': 10, 'answer_dropout_p': 0.1, 'answer_weight_norm_on': False, 'dump_state_on': False, 'answer_opt': 1, 'pooler_actf': 'tanh', 'mtl_opt': 1, 'ratio': 0, 'mix_opt': 0, 'max_seq_len': 512, 'init_ratio': 1, 'encoder_type': 2, 'num_hidden_layers': -1, 'bert_model_type': 'roberta', 'FileOut': None, 'do_lower_case': False, 'masked_lm_prob': 0.15, 'short_seq_prob': 0.2, 'max_predictions_per_seq': 128, 'bin_on': False, 'bin_size': 64, 'bin_grow_ratio': 0.5, 'local_rank': -1, 'world_size': 1, 'master_addr': 'localhost', 'master_port': '6600', 'backend': 'nccl', 'cuda': False, 'log_per_updates': 500, 'save_per_updates': 10000, 'save_per_updates_on': False, 'epochs': 10, 'batch_size': 8, 'batch_size_eval': 8, 'optimizer': 'adamax', 'grad_clipping': 1.0, 'global_grad_clipping': 1.0, 'weight_decay': 0, 'learning_rate': 5e-05, 'momentum': 0, 'warmup': 0.1, 'warmup_schedule': 'warmup_linear', 'adam_eps': 1e-07, 'vb_dropout': True, 'dropout_p': 0.1, 'dropout_w': 0.0, 'bert_dropout_p': 0.1, 'model_ckpt': 'checkpoints/model_0.pt', 'resume': False, 'have_lr_scheduler': True, 'multi_step_lr': '10,20,30', 'lr_gamma': 0.5, 'scheduler_type': 'ms', 'output_dir': 'Addestramento', 'seed': 2010, 'grad_accumulation_step': 1, 'fp16': False, 'fp16_opt_level': 'O1', 'adv_train': False, 'adv_opt': 0, 'adv_norm_level': 0, 'adv_p_norm': 'inf', 'adv_alpha': 1, 'adv_k': 1, 'adv_step_size': 1e-05, 'adv_noise_var': 1e-05, 'adv_epsilon': 1e-06, 'encode_mode': False, 'debug': False, 'task_def_list': [{'self': '{}', 'label_vocab': '<data_utils.vocab.Vocabulary object at 0x7f774fd3c110>', 'n_class': '5', 'data_type': '<DataFormat.PremiseOnly: 1>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>, <Metric.F1_ddi: 14>, <Metric.Precision_ddi: 16>, <Metric.Recall_ddi: 19>)', 'split_names': \"['train', 'dev', 'test']\", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': \"<class 'experiments.exp_def.TaskDef'>\"}, {'self': '{}', 'label_vocab': '<data_utils.vocab.Vocabulary object at 0x7f774fd3c150>', 'n_class': '6', 'data_type': '<DataFormat.PremiseOnly: 1>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>, <Metric.F1_chem: 12>, <Metric.Precision_chem: 15>, <Metric.Recall_chem: 18>)', 'split_names': \"['train', 'dev', 'test']\", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': \"<class 'experiments.exp_def.TaskDef'>\"}, {'self': '{}', 'label_vocab': '<data_utils.vocab.Vocabulary object at 0x7f774fd3c2d0>', 'n_class': '9', 'data_type': '<DataFormat.PremiseOnly: 1>', 'task_type': '<TaskType.Classification: 1>', 'metric_meta': '(<Metric.ACC: 0>, <Metric.F1_i2b2: 13>, <Metric.Precision_i2b2: 17>, <Metric.Recall_i2b2: 20>)', 'split_names': \"['train', 'dev', 'test']\", 'enable_san': 'False', 'dropout_p': 'None', 'loss': '<LossCriterion.CeCriterion: 0>', 'kd_loss': '<LossCriterion.MseCriterion: 1>', 'adv_loss': '<LossCriterion.SymKlCriterion: 7>', '__class__': \"<class 'experiments.exp_def.TaskDef'>\"}]}\n",
            "10/09/2021 09:25:45 ####################\n",
            "8773\n",
            "10/09/2021 09:25:45 ############# Gradient Accumulation Info #############\n",
            "10/09/2021 09:25:45 number of step: 87730\n",
            "10/09/2021 09:25:45 number of grad grad_accumulation step: 1\n",
            "10/09/2021 09:25:45 adjusted number of step: 87730\n",
            "10/09/2021 09:25:45 ############# Gradient Accumulation Info #############\n",
            "qui\n",
            "mt_dnn_models/robertaFB/model.pt\n",
            "10/09/2021 09:25:50 \n",
            "############# Model Arch of MT-DNN #############\n",
            "SANBertNetwork(\n",
            "  (dropout_list): ModuleList(\n",
            "    (0): DropoutWrapper()\n",
            "    (1): DropoutWrapper()\n",
            "    (2): DropoutWrapper()\n",
            "  )\n",
            "  (bert): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50008, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): RobertaPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (scoring_list): ModuleList(\n",
            "    (0): Linear(in_features=768, out_features=5, bias=True)\n",
            "    (1): Linear(in_features=768, out_features=6, bias=True)\n",
            "    (2): Linear(in_features=768, out_features=9, bias=True)\n",
            "  )\n",
            "  (pooler): Pooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (dropout): DropoutWrapper()\n",
            "  )\n",
            ")\n",
            "\n",
            "10/09/2021 09:25:50 Total number of params: 125054228\n",
            "10/09/2021 09:25:50 At epoch 0\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n",
            "10/09/2021 09:26:05 Task [ 1] updates[     1] train loss[2.00575] remaining[1 day, 13:39:47]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 546, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 506, in main\n",
            "    model.update(batch_meta, batch_data)\n",
            "  File \"/content/Multi-task-Learning-for-Biomedical-Relation-Extraction/mt-dnn/mt_dnn/model.py\", line 317, in update\n",
            "    self.optimizer.step()\n",
            "  File \"/content/Multi-task-Learning-for-Biomedical-Relation-Extraction/mt-dnn/module/bert_optim.py\", line 227, in step\n",
            "    torch.max(norm_buf, 0, keepdim=False, out=(exp_inf, exp_inf.new().long()))\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGDGvykUeNKg"
      },
      "source": [
        "Example of MTL few shot learning. As always, tokenization is required first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w4AAsRFeQUs"
      },
      "source": [
        "!python train.py --task_def tutorials/tutorial_task_def.yml --data_dir \"Directory_SHOT_tokenizzati\"   --train_datasets ddi2013 --test_datasets ddi2013  --epochs=30 --batch_size=8 --bert_model_type=\"roberta\"  --encoder_type=2  --output_dir=\"AddestramentoFewShot\" --init_checkpoint=\"mt_dnn_models/robertaFB\" --grad_clipping=1.0 --adam_eps=1e-7 --seed=9   #--model_ckpt=\"SingleTaskI2B2MEDIUMFiltrato10BERT81MIL2000/model_6.pt\" --resume\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2wGuV-OgLyu"
      },
      "source": [
        "In this case, adversarial learning is performed on the few shot with the adv_opt and adv parameters. The losses can be modified from the loss file in the mt-dnn directory and then in the tutorial_def.yml file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8-36lJPgBAY"
      },
      "source": [
        "!python train.py --task_def tutorials/tutorial_task_def.yml --data_dir \"Directory_SHOT_tokenizzati\"   --train_datasets ddi2013,chemprot,i2b2 --test_datasets ddi2013,chemprot,i2b2  --epochs=30 --batch_size=8 --bert_model_type=\"roberta\"  --encoder_type=2  --output_dir=\"AddestramentoFewShotMTL\" --init_checkpoint=\"mt_dnn_models/RobertaVoc/RobertaVoc2/\" --grad_clipping=1.0 --adam_eps=1e-7 --seed=9  --adv=1 --adv_opt=1 #--model_ckpt=\"SingleTaskI2B2MEDIUMFiltrato10BERT81MIL2000/model_6.pt\" --resume\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD9c4lJWef4B"
      },
      "source": [
        "The evaluation on the test set can be performed simultaneously with the training. In the train.py file, the part related to this needs to be uncommented. However, given the huge training times, it is recommended to perform the prediction phase afterwards, predicting on the model that has the best performance on the validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxPYEP7Oe0Y3"
      },
      "source": [
        "The predict.py script can be used without many modifications when making predictions on a model trained on a single task. When using a multi-task model, you first need to load a single task model and then initialize it with the weights of the multi-task model, using the corresponding multi-task layer as the output layer. This can be set in the initial part of the predict.py script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb7OwWt8t1dW"
      },
      "source": [
        "#predict\n",
        "!python predict.py --task_def tutorials/tutorial_task_def.yml --task chemprot --task_id=0 --prep_input=\"tutorials/robertaFB/chemprot_train.json\" --score=\"ScoreRidotto/ScoreChemprotAssistantT4.txt\"  --model_checkpoint=\"MTL01F2040/model_9.pt\" --checkpoint=\"ChemprotSingleF2000/model_9.pt\"  --with_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmMZfAgEfzI_"
      },
      "source": [
        "Knowledge distillation phase. This code does not work if the input data, already tokenized in .json, do not have a soft label column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miYi4UgVy1XI"
      },
      "source": [
        "!python train.py --task_def tutorials/tutorial_task_def.yml --data_dir tutorials/robertaFB/   --train_datasets ddi2013,chemprot,i2b2 --test_datasets ddi2013,chemprot,i2b2 --epochs=10 --batch_size=8 --bert_model_type=\"roberta\"  --encoder_type=2  --output_dir=\"Addestramento\" --init_checkpoint=\"mt_dnn_models/RobertaFB\" --grad_clipping=1.0 --adam_eps=1e-7  --seed=2000 --mtl_opt=1 --mkd_opt=1   #--model_ckpt=\"SingleI2B2SEED2040/model_2.pt\" --resume"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z5P54Sjgt9t"
      },
      "source": [
        "The json file with the soft label columns is obtained through an offline mechanism. First, prediction is made on the test set using the predict.py script for the task of interest. Then, the prepare_distillation_data.py script is used to obtain the soft labels. The soft labels will then be concatenated with the already tokenized dataset json file and given as input to the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeXhs0P4lGOx"
      },
      "source": [
        "#Example of creating soft labels for chemprot. The prepare distillation file needs to be properly set for the type of task required. \n",
        "!python prepare_distillation_data.py  --task_def tutorials/tutorial_task_def.yml --task chemprot --add_soft_label --std_input=\"tutorials/chemprot_train.tsv\" --score=\"ScoreEnsemble/Chemprot012000.txt\" --std_output=\"ScoreEnsemble/Distillati/Chemprot012000.txt\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbXxihWFoSSz"
      },
      "source": [
        "Subsequently, the training dataset's JSON file is read, the newly determined soft label's txt file is read, and they are concatenated, resulting in the file that is required for distilled training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPZV55KXZ0TL"
      },
      "source": [
        "**Task Analysis ** : The similarity between the datasets will be calculated through the sentence embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuxQgHcCaB_u"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12')\n",
        "print(\"Max Sequence Length:\", model.max_seq_length)\n",
        "model.max_seq_length = 512\n",
        "print(\"Max Sequence Length:\", model.max_seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_GPc9Qbc7e2"
      },
      "source": [
        "import pandas as pd\n",
        "DatasetTrainDDI2013=pd.read_csv(\"Multi-task-Learning-for-Biomedical-Relation-Extraction/Dataset/DDI2013/ddi2013_train.tsv\", sep='\\t',header=None)\n",
        "DatasetTrainChemprot=pd.read_csv(\"Multi-task-Learning-for-Biomedical-Relation-Extraction/Dataset/Chemprot/chemprot_train.tsv\", sep='\\t',header=None)\n",
        "DatasetTrainI2B2=pd.read_csv(\"Multi-task-Learning-for-Biomedical-Relation-Extraction/Dataset/I2B2-2010RE/i2b2_train.tsv\", sep='\\t',header=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcemf_aQclOG"
      },
      "source": [
        "SentencesDDI=[]\n",
        "for i in range(len(DatasetTrainDDI2013)):\n",
        "  SentencesDDI.append(DatasetTrainDDI2013[0][i])\n",
        "print(SentencesDDI[0:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyH1CJVacmI4"
      },
      "source": [
        "SentencesChemprot=[]\n",
        "for i in range(len(DatasetTrainChemprot)):\n",
        "  SentencesChemprot.append(DatasetTrainChemprot[0][i])\n",
        "print(SentencesChemprot[0:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea8oOOafco71"
      },
      "source": [
        "SentencesI2B2=[]\n",
        "for i in range(len(DatasetTrainI2B2)):\n",
        "  SentencesI2B2.append(DatasetTrainI2B2[0][i])\n",
        "print(SentencesI2B2[0:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf-VcBOqcbQi"
      },
      "source": [
        "sentences encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUNOSYeoccmX"
      },
      "source": [
        "sentence_embeddingsDDI = model.encode(SentencesDDI)\n",
        "sentence_embeddingsCHEM = model.encode(SentencesChemprot)\n",
        "sentence_embeddingsI2B2 = model.encode(SentencesI2B2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjAGDItTgHrC"
      },
      "source": [
        "Similarity between DDI amd Chemprot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtOv9bLIf1q1"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "score_DDICHEM=[]\n",
        "for i in range(len(SentencesDDI)):\n",
        "  score_DDICHEM.append(np.sum(cosine_similarity(\n",
        "      [sentence_embeddingsDDI[i]],\n",
        "      sentence_embeddingsCHEM[1:]\n",
        "  ))/len(SentencesChemprot))\n",
        "print(score_DDICHEM) #poi dovrei fare la somma e dividere sti valori"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFe95LN7gN1S"
      },
      "source": [
        "import numpy as np\n",
        "np.sum(score_DDICHEM)/len(SentencesDDI)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
